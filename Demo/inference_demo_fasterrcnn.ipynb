{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import json\n",
    "\n",
    "class GunDataset(Dataset):\n",
    "    def __init__(self, image_dir, annotation_dir, transform=None, train=True):\n",
    "      with open(annotation_dir, \"r\") as f:\n",
    "        coco_data = json.load(f)\n",
    "      self.image_dir = image_dir\n",
    "      self.transform = transform\n",
    "      self.train = train\n",
    "      self.images = coco_data['images']\n",
    "      self.annotations = coco_data['annotations']\n",
    "      self.categories = {}\n",
    "      self.id_to_name = {}\n",
    "      \n",
    "      for category in coco_data['categories']:\n",
    "          new_id = len(self.categories) + 1\n",
    "          self.categories[category['id']] = new_id\n",
    "          self.id_to_name[new_id] = category['name']\n",
    "      \n",
    "      print(\"Categorie trovate:\")\n",
    "      for new_id, name in self.id_to_name.items():\n",
    "          print(f\"- {name}: {new_id}\")\n",
    "      \n",
    "      # Crea il mapping immagine -> annotazioni (solo per armi)\n",
    "      self.img_to_anns = {img['id']: [] for img in self.images}\n",
    "      for ann in self.annotations:\n",
    "          self.img_to_anns[ann['image_id']].append(ann)\n",
    "      \n",
    "      self.images = [img for img in self.images if len(self.img_to_anns[img['id']]) > 0]\n",
    "      \n",
    "      print(f\"Immagini totali con armi: {len(self.images)}\")\n",
    "      print(f\"Annotazioni di armi totali: {len(self.annotations)}\")\n",
    "      \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "      \n",
    "    def __getitem__(self, idx):\n",
    "        image_path = os.path.join(self.image_dir, str(self.images[idx]['file_name']))\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        \n",
    "        img_id = self.images[idx]['id']\n",
    "        annotations = self.img_to_anns[img_id]\n",
    "        \n",
    "        # Conversione annotazioni COCO in Pascal VOC\n",
    "        boxes = []\n",
    "        labels = []  \n",
    "        for ann in annotations:\n",
    "            x, y, w, h = ann['bbox']\n",
    "            boxes.append([x, y, x + w, y + h])\n",
    "            labels.append(self.categories[ann['category_id']])\n",
    "        \n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "        labels = torch.as_tensor(labels, dtype=torch.int64)\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, boxes, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "train_dataset_folder = \"../Dataset/fasterrcnn/train\"\n",
    "\n",
    "transform = A.Compose([\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "train_dataset = GunDataset(train_dataset_folder, train_dataset_folder+\"/_annotations.coco.json\", transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "import os\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = fasterrcnn_resnet50_fpn(weights=None)\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes=len(train_dataset.categories) + 1)\n",
    "\n",
    "model_path = '../Models/best_model_fasterrcnn_base.pth'\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "\n",
    "def apply_nms(boxes, scores, iou_threshold=0.5):\n",
    "    keep_indices = torchvision.ops.nms(boxes, scores, iou_threshold)\n",
    "    return keep_indices.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as T\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "def load_image(image_path):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    transform = T.Compose([T.ToTensor(), T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "    image_tensor = transform(image)\n",
    "    return image, image_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import ImageDraw, ImageFont\n",
    "\n",
    "def visualize_prediction(image, boxes, scores, labels, threshold=0.5, id_to_name=None):\n",
    "    draw_image = image.copy()\n",
    "    draw = ImageDraw.Draw(draw_image)\n",
    "    \n",
    "    try:\n",
    "        font = ImageFont.truetype('arial.ttf', 20)\n",
    "    except IOError:\n",
    "        font = ImageFont.load_default()\n",
    "    \n",
    "    filtered_boxes = []\n",
    "    filtered_scores = []\n",
    "    filtered_labels = []\n",
    "    \n",
    "    for box, score, label in zip(boxes, scores, labels):\n",
    "        if score >= threshold:\n",
    "            filtered_boxes.append(box)\n",
    "            filtered_scores.append(score)\n",
    "            filtered_labels.append(label)\n",
    "    \n",
    "    for box, score, label in zip(filtered_boxes, filtered_scores, filtered_labels):\n",
    "        x1, y1, x2, y2 = box\n",
    "        \n",
    "        draw.rectangle([(x1, y1), (x2, y2)], outline=\"red\", width=3)\n",
    "        \n",
    "        class_name = id_to_name[label]\n",
    "        label_text = f\"{class_name}: {score:.2f}\"\n",
    "        draw.text((x1, y1-25), label_text, fill=\"red\", font=font)\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.imshow(np.array(draw_image))\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    return draw_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_guns(image_path, confidence_threshold=0.5, id_to_name=train_dataset.id_to_name):\n",
    "    original_image, image_tensor = load_image(image_path)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        prediction = model([image_tensor.to(device)])\n",
    "    \n",
    "    boxes = prediction[0]['boxes'].cpu().numpy()\n",
    "    scores = prediction[0]['scores'].cpu().numpy()\n",
    "    labels = prediction[0]['labels'].cpu().numpy()\n",
    "    \n",
    "    keep_indices = apply_nms(torch.tensor(boxes), torch.tensor(scores), iou_threshold=0.2)\n",
    "    \n",
    "    boxes = boxes[keep_indices]\n",
    "    scores = scores[keep_indices]\n",
    "    labels = labels[keep_indices]\n",
    "    \n",
    "    result_image = visualize_prediction(original_image, boxes, scores, labels, \n",
    "                                      confidence_threshold, id_to_name)\n",
    "    \n",
    "    return {\n",
    "        'boxes': boxes,\n",
    "        'scores': scores,\n",
    "        'labels': labels,\n",
    "        'result_image': result_image\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    test_images = os.listdir(\"demo_images\")\n",
    "    test_images = [os.path.join(\"demo_images/\", image) for image in test_images]\n",
    "    guns_detected = 0\n",
    "    \n",
    "    for image_path in test_images:\n",
    "        print(f\"Esecuzione rilevamento armi su: {image_path}\")\n",
    "        results = detect_guns(image_path, confidence_threshold=0.6)\n",
    "        guns_detected += sum(1 for score in results['scores'] if score >= 0.6)\n",
    "        \n",
    "    print(f\"Armi rilevate: {guns_detected}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
